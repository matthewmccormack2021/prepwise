services:
  frontend-service:
    build:
      context: .
      dockerfile: ./services/frontend-service/Dockerfile
    ports:
      - "8501:8501"
    environment:
      - PYTHONPATH=/app
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
    volumes:
      - ./services/frontend-service/logs:/app/logs
    depends_on:
      - backend-service
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - prepwise-network

  backend-service:
    build:
      context: .
      dockerfile: ./services/backend-service/Dockerfile
    ports:
      - "8002:8002"
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://host.docker.internal:11434
    volumes:
      - ./services/backend-service/logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - prepwise-network
  transcription-service:
    image: onerahmet/openai-whisper-asr-webservice:latest
    ports:
      - "9000:9000"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=openai_whisper
    restart: unless-stopped
    networks:
      - prepwise-network

networks:
  prepwise-network:
    driver: bridge
